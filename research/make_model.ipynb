{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6jDvO_OO8zs"
      },
      "source": [
        "<h3>Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ncSPAf_0O8zu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/egemenipek/projects/aylien-science-challenge-master/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from collections import Counter\n",
        "import statistics\n",
        "import random\n",
        "import re\n",
        "import spacy\n",
        "import typing\n",
        "from typing import List, Tuple, Dict\n",
        "from transformers import CanineTokenizer, CanineModel, CanineForSequenceClassification\n",
        "from datasets import Dataset, DatasetDict\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'3.7.5'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spacy.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vGBSR07O8zw"
      },
      "source": [
        "<h3>Work directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mm-5edpSO8zw",
        "outputId": "16a6068d-94d3-4692-e056-c93212c113c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Changed working directory to '/Users/egemenipek/projects/aylien-science-challenge-master'\n"
          ]
        }
      ],
      "source": [
        "# directory path\n",
        "directory = '/Users/egemenipek/projects/aylien-science-challenge-master'\n",
        "\n",
        "# Check if the directory exists\n",
        "if os.path.exists(directory):\n",
        "    # Change the current working directory to the specified directory\n",
        "    os.chdir(directory)\n",
        "    print(f\"Changed working directory to '{directory}'\")\n",
        "else:\n",
        "    print(f\"Directory '{directory}' does not exist\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m0t6uJcO8zw"
      },
      "source": [
        "<h1>Prepare Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "zRN3aq3kO8zw"
      },
      "outputs": [],
      "source": [
        "# this function reads a .txt file\n",
        "# it is meant to work with on a document-per-line basis as in the sample data files provided\n",
        "def read_data(path: str) -> List[str]:\n",
        "    with open(path, 'r') as f:\n",
        "        text = f.read()\n",
        "        documents = text.split('\\n')\n",
        "        return documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "m-gt4IskO8zw"
      },
      "outputs": [],
      "source": [
        "positive = read_data(\"data/positive\")\n",
        "neutral = read_data('data/neutral')\n",
        "negative = read_data('data/negative')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzGOIlccO8zx",
        "outputId": "fac385e9-4e2d-4ad1-db21-c5d17e9987b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive Examples:2364\n",
            "Neutral Examples:3100\n",
            "Negative Examples: 9179\n"
          ]
        }
      ],
      "source": [
        "# observing data distribution\n",
        "print(f'Positive Examples:{len(positive)}\\nNeutral Examples:{len(neutral)}\\nNegative Examples: {len(negative)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJtYRzEaO8zx"
      },
      "source": [
        "There is significant class imbalance towards Negative examples. Neutral examples are, although not as significant as the class Negative, still have significantly more examples than the positive class.\n",
        "<p> It makes sense here to over-sample less represented classes and under-sample the more represented class into the standard deviation value of n_examples across three of the classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_QrARWkRO8zx"
      },
      "outputs": [],
      "source": [
        "n_examples = [len(positive), len(neutral), len(negative)]\n",
        "std_dev = int(statistics.stdev(n_examples)) #std stands for standard deviation I'm not trying to tell a story here :D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "unvQIgAcO8zx"
      },
      "outputs": [],
      "source": [
        "def over_sample(target_n_examples: int, data: List[str]) -> List[str]:\n",
        "    current_n_examples = len(data) #the number of examples in the dataset\n",
        "    required_n_examples = target_n_examples - current_n_examples #required number of data examples required to oversample to reach standard deviation\n",
        "    random_idxs = [random.randint(0, current_n_examples-1) for i in range(required_n_examples)] #get random indicies for oversampling\n",
        "    required_examples = [data[i] for i in random_idxs] # the list of oversample data to be merged into the existing data\n",
        "    oversampled_data = data + required_examples\n",
        "    return oversampled_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "LewuNko7O8zx"
      },
      "outputs": [],
      "source": [
        "def under_sample(target_n_examples: int,  data: List[str]) -> List[str]:\n",
        "    current_n_examples = len(data) #the number of examples in the data\n",
        "    random_idxs = [random.randint(0, current_n_examples-1) for i in range(target_n_examples)] #get random indecies to include in the data\n",
        "    undersampled_data = [data[i] for i in random_idxs] #make new data with the random indicies\n",
        "    return undersampled_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbOTXBpUO8zx"
      },
      "source": [
        "Apply oversampling and undersampling to the classes Positive, Neutral, and Negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "mldhvphOO8zx"
      },
      "outputs": [],
      "source": [
        "positive_std = over_sample(std_dev, positive)\n",
        "neutral_std = over_sample(std_dev, neutral)\n",
        "negative_std = under_sample(std_dev, negative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCIBVSEnO8zx",
        "outputId": "3ae53bc3-7ddd-4081-8b0b-45f96b69036f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive Examples:3740\n",
            "Neutral Examples:3740\n",
            "Negative Examples: 3740\n"
          ]
        }
      ],
      "source": [
        "# observing data distribution\n",
        "print(f'Positive Examples:{len(positive_std)}\\nNeutral Examples:{len(neutral_std)}\\nNegative Examples: {len(negative_std)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmA2NTzRO8zy"
      },
      "source": [
        "<h3>Text Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdWNRKlnO8zy"
      },
      "source": [
        "<p>Preprocessing is going to be essential since the model is character-level"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQNnu5kKO8zy"
      },
      "source": [
        "Pre-processing strats:\n",
        "* Numbers out -done\n",
        "* Stopwords out -done\n",
        "* Punctuation out -done\n",
        "* URLs need to go -done\n",
        "* Userhandles out - done\n",
        "* Lemmatize the tokens -done\n",
        "* Remove named entities - done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "eH0YaMr-O8zy"
      },
      "outputs": [],
      "source": [
        "# use spacy to remove stopwords\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "CBhUtCbgO8zy"
      },
      "outputs": [],
      "source": [
        "# this function removes numbers from a list of strings\n",
        "def remove_numbers(data: List[str]) -> List[str]:\n",
        "    clean_data = []\n",
        "    pattern = r'\\d+'\n",
        "    for document in data:\n",
        "        document = re.sub(pattern, '', document)\n",
        "        clean_data.append(document)\n",
        "    return clean_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "iIQ55yd3O8zy"
      },
      "outputs": [],
      "source": [
        "# this function removes handle content from documents example: @someuser\n",
        "def remove_handle_content(data: List[str]) -> List[str]:\n",
        "    clean_data = []\n",
        "    for document in data:\n",
        "        document = ' '.join([token for token in document.split() if '@' not in token])\n",
        "        clean_data.append(document)\n",
        "    return clean_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "BigugeiIO8zy"
      },
      "outputs": [],
      "source": [
        "# this function removes url content from documents example: http//:someurl\n",
        "def remove_url_content(data: List[str]) -> List[str]:\n",
        "    clean_data = []\n",
        "    for document in data:\n",
        "        document = ' '.join([token for token in document.split() if token[:4]!='http'])\n",
        "        clean_data.append(document)\n",
        "    return clean_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "x9o-X-A9O8zy"
      },
      "outputs": [],
      "source": [
        "# this function removes stopwords and punctuation from documents example: the !, etc.\n",
        "def remove_stopwords_punctuation(data: List[str]) -> List[str]:\n",
        "    clean_data = []\n",
        "    for document in data:\n",
        "        doc = nlp(document)\n",
        "        document = ' '.join([token.text for token in doc if not token.is_stop and not token.is_punct])\n",
        "        clean_data.append(document)\n",
        "    return clean_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "dg55oNOhO8zy"
      },
      "outputs": [],
      "source": [
        "# this function removed named entities form the example\n",
        "def remove_entities(data: List[str]) -> List[str]:\n",
        "    clean_data = []\n",
        "    for document in data:\n",
        "        doc = nlp(document)\n",
        "        document = ' '.join([token.text for token in doc if not token.ent_type_])\n",
        "        clean_data.append(document)\n",
        "    return clean_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "vGW-5c6KO8zy"
      },
      "outputs": [],
      "source": [
        "# this function lemmatizes tokens in the documents inside the data example: going -> go # this also lowercases letters\n",
        "# this function also removes duplicate tokens\n",
        "def lemmatize_documents(data: List[str]) -> List[str]:\n",
        "    clean_data = []\n",
        "    for document in data:\n",
        "        doc = nlp(document)\n",
        "        document = ' '.join([token.lemma_.lower() for token in doc])\n",
        "        clean_data.append(document)\n",
        "    return clean_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "8ypDN-jhO8zy"
      },
      "outputs": [],
      "source": [
        "# this function filters tokens based on designated POS tags I decided not to use it\n",
        "def filter_pos(data: List[str]) -> List[str]:\n",
        "    pos_tags_to_keep = [\"ADJ\", \"ADV\", \"INTJ\", \"VERB\"]\n",
        "    clean_data = []\n",
        "    for document in data:\n",
        "        doc = nlp(document)\n",
        "        document = ' '.join([token.text for token in doc if token.pos_ in pos_tags_to_keep])\n",
        "        clean_data.append(document)\n",
        "    return clean_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrL5VVfoO8zy"
      },
      "source": [
        "Apply text preprocessing functions to existing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "8iN-_Rt4O8zy"
      },
      "outputs": [],
      "source": [
        "positive_clean = lemmatize_documents(remove_entities(remove_stopwords_punctuation(remove_url_content(remove_handle_content(remove_numbers(positive_std))))))\n",
        "neutral_clean = lemmatize_documents(remove_entities(remove_stopwords_punctuation(remove_url_content(remove_handle_content(remove_numbers(neutral_std))))))\n",
        "negative_clean = lemmatize_documents(remove_entities(remove_stopwords_punctuation(remove_url_content(remove_handle_content(remove_numbers(negative_std))))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYQ227LKO8zy",
        "outputId": "b0017879-9b45-4ab2-e388-dc3165a434fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive:\n",
            "@united that's brilliant Thankyou so much. Is it classed as part of carryon? \n",
            " brilliant classed carryon\n",
            "Neutral:\n",
            "@united DM sent \n",
            " dm send\n",
            "Negative:\n",
            "@USAirways stuck on the ramp at DCA, US Air computer system crashed...everywhere. \n",
            " stick ramp computer system crash\n"
          ]
        }
      ],
      "source": [
        "idx = 230\n",
        "print('Positive:')\n",
        "print(positive_std[idx],'\\n', positive_clean[idx])\n",
        "print('Neutral:')\n",
        "print(neutral_std[idx],'\\n', neutral_clean[idx])\n",
        "print('Negative:')\n",
        "print(negative_std[idx],'\\n', negative_clean[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5Dz0PEBO8zy"
      },
      "source": [
        "<h3>Populate dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "hvpzRzpqO8zy"
      },
      "outputs": [],
      "source": [
        "# this function takes in a list of examples and pairs it with a label integer to make a tuple(str, int)\n",
        "def add_label(data: List[str], label: int) -> Tuple[str, int]:\n",
        "    text_label_pair = []\n",
        "    for example in data:\n",
        "        example = (example, label)\n",
        "        text_label_pair.append(example)\n",
        "    return text_label_pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "X3LVjcpUO8zy"
      },
      "outputs": [],
      "source": [
        "# put data together into a single object\n",
        "positive_data = add_label(positive_clean, 0)\n",
        "neutral_data = add_label(neutral_clean, 1)\n",
        "negative_data = add_label(negative_clean, 2)\n",
        "dataset = positive_data + neutral_data + negative_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrjgh3JzO8zz",
        "outputId": "d5ffdb9a-431e-43d4-df70-d99038905996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3740 3740 3740\n",
            "11220 11220\n",
            "('try book flight amp site 😁', 2)\n"
          ]
        }
      ],
      "source": [
        "print(len(positive_data), len(neutral_data), len(negative_data))\n",
        "print(len(positive_data) + len(neutral_data) + len(negative_data), len(dataset))\n",
        "print(dataset[8000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "Tt2OodPdO8zz",
        "outputId": "499aa291-e7f0-4ebb-a4fb-5a3750b3d461"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>plus add commercial experience tacky</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yes nearly time fly ear worm will away</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     text  label\n",
              "0    plus add commercial experience tacky      0\n",
              "1  yes nearly time fly ear worm will away      0"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# make a dataframe for the train_test_split function from sklearn and to save the dataset\n",
        "dataset_df = pd.DataFrame(dataset, columns=['text', 'label'])\n",
        "dataset_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tt1OkTQIO8zz",
        "outputId": "f49a701e-0c67-4ccc-d48f-dba0c95b929d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 11220\n",
              "})"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load data from the dataframe into the huggingface dataset object\n",
        "ds = Dataset.from_pandas(dataset_df)\n",
        "ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoKHB7uQO8zz"
      },
      "source": [
        "<h1>Create Sentiment Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKsiq9ABO8zz"
      },
      "source": [
        "We don't have data to pre-train a transformer encoder stack. Therefore we only can opt for a pre-trained model.\n",
        "<p>I've found this character-based transformer from Google named Canine-s, here's the model card: https://huggingface.co/google/canine-s\n",
        "\n",
        "<p>We will add a linear layer (the classifier head) to the base model and fine-tune it with our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6Sz_hePO8z3"
      },
      "source": [
        "<h3>Google Canine-s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaARdcp3O8z3",
        "outputId": "d41d6548-2486-4888-d11f-7db9fe4f1f85"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# this model creates 2048 dimensional tensors\n",
        "tokenizer = CanineTokenizer.from_pretrained('google/canine-s') #load it's tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "TmnrQOYuO8z3"
      },
      "outputs": [],
      "source": [
        "# this is a tokenizer function, this is how huggingface recommends tokenizing examples\n",
        "def tokenizer_fn(example):\n",
        "    return tokenizer(example['text'], padding='max_length', truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8cd3718be5584301b4feb9cd17d81b4b",
            "196d6fb3740b49d8ad17b7117b51914c",
            "72dd9e346ded45c5baa14cdba7b89a66",
            "8ca20062229242cc9e17861d8daf7292",
            "39b29efcfce44182accc20c093986ae6",
            "39e3ae1c89824f91aadbb5ed3f70ef2c",
            "07b14a7240ff4534b4cffa4ae1002c08",
            "9f4cbfe626154dfd8544849a613453e1",
            "02e03b3d8bbe4791a146e5ec2069729a",
            "ecdc160026404387bded81ea8a78a81c",
            "c74f869346ad47a7afbcf3d89a1e6f22"
          ]
        },
        "id": "Se1ijjnRO8z3",
        "outputId": "a93f553b-4306-45c1-d6c9-aea4abcd8e58"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cd3718be5584301b4feb9cd17d81b4b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/11220 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# recommended implementation of the tokenizer function\n",
        "ds_tokenized = ds.map(tokenizer_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4v9DkcFO8z3",
        "outputId": "bf742dd3-9f13-4952-b49e-5b4ccd1d5ea4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask']\n"
          ]
        }
      ],
      "source": [
        "#observe new columns\n",
        "print(ds_tokenized.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xd2TqFbjO8z3",
        "outputId": "6c6e50a4-a75c-4587-b357-a4c77ada4958"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['labels', 'input_ids', 'token_type_ids', 'attention_mask']\n"
          ]
        }
      ],
      "source": [
        "# need to take the 'text' column out because the model will give an error otherwise. It doesn't expenct this column\n",
        "# it is very important that the column for labels is named 'labels' for the same reason\n",
        "ds_tokenized = ds_tokenized.remove_columns(['text'])\n",
        "ds_tokenized = ds_tokenized.rename_column('label', 'labels')\n",
        "ds_tokenized.set_format('torch') #set tensor format to torch because we'll be using torch in this project\n",
        "print(ds_tokenized.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "OweEciOUO8z3"
      },
      "outputs": [],
      "source": [
        "# split the dataset to train, val, test\n",
        "# first we split the test and train+val subsets and then we split train+val into train and val subsets\n",
        "ds_traintest = ds_tokenized.train_test_split(test_size=0.1)\n",
        "ds_trainval = ds_traintest['train'].train_test_split(test_size=0.2)\n",
        "ds_train = ds_trainval['train']\n",
        "ds_val = ds_trainval['test']\n",
        "ds_test = ds_traintest['test']  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auoUs0OBO8z3",
        "outputId": "8793eabe-1f4e-4c82-c52c-a2f60a6cf50c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "    num_rows: 8078\n",
            "}) Dataset({\n",
            "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "    num_rows: 2020\n",
            "}) Dataset({\n",
            "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
            "    num_rows: 1122\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# observe datasets\n",
        "print(ds_train, ds_val, ds_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "cu0_k0lZO8z3"
      },
      "outputs": [],
      "source": [
        "# make dataloaders from our datasets\n",
        "train_dataloader = DataLoader(ds_train, batch_size=4, shuffle=True)\n",
        "val_dataloader = DataLoader(ds_val, batch_size=4, shuffle=True)\n",
        "test_dataloader = DataLoader(ds_test, batch_size=4, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_BRP1UcO8z3",
        "outputId": "cd77ea23-5a08-4789-8f20-3d1494fc823e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CanineForSequenceClassification were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "sentiment_classifier = CanineForSequenceClassification.from_pretrained('google/canine-s', num_labels=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Auc5ySyLO8z3",
        "outputId": "e34f02d3-38ec-4e65-e695-788ca493e823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# initialize the model and make general settings\n",
        "#sentiment_classifier = Classifier()\n",
        "num_epochs = 1\n",
        "num_iterations = num_epochs * ds_train.num_rows\n",
        "optimizer = optim.AdamW(sentiment_classifier.parameters(), lr=2e-5)\n",
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "sentiment_classifier.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "mmsdD_GhO8z3"
      },
      "outputs": [],
      "source": [
        "softmax = nn.Softmax(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "d2256e6300344d24b3b212f7a386b70c",
            "ffc13ba68c1c4cefb543007cd90f9843",
            "4cb178c5d0ab476c8523928e7d6f8ca3",
            "adbd31d9e7564726a0c84ea76d2ebd06",
            "459af651996544d0b8e1990f2fb8b71c",
            "cfdbd2e6996042208e85c1d0c24e56fa",
            "240dc895adcd4deebe62c586fa79a9af",
            "8f1761b1136f4bc394057324f99791d4",
            "4a2d3b85d2434bfdbfd43e96287da1c8",
            "041df3b1f5de49b094dbff6d88a5291b",
            "056af4b800064da183e3bc73e9f52e40"
          ]
        },
        "id": "YLSSAEACO8z3",
        "outputId": "131c885c-e065-48b7-9f76-c9cf7f80f283"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2256e6300344d24b3b212f7a386b70c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/8078 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Accuracy: 0.9535776182223322, Precision: 0.9536551972199313, Recall: 0.9537904891681773, F1 Macro: 0.9535690954592821, F1 Micro: 0.9535776182223322\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "progress_bar = tqdm(range(num_iterations))\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    sentiment_classifier.train()\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        batch_labels = batch['labels'].to(device)\n",
        "        outputs = sentiment_classifier(**batch)\n",
        "        logits = outputs.logits\n",
        "        #print(logits)\n",
        "        loss = loss_fn(logits, batch_labels)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        optimizer.zero_grad()   \n",
        "        progress_bar.update(1)\n",
        "\n",
        "    sentiment_classifier.eval()\n",
        "    y_preds = []\n",
        "    ys = []\n",
        "    for batch in val_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        batch_labels = batch['labels']\n",
        "        with torch.no_grad():\n",
        "            outputs = sentiment_classifier(**batch)\n",
        "            logits = outputs.logits\n",
        "            #print(logits)\n",
        "            #print(logits.shape)\n",
        "            #print(logits.device)\n",
        "            #print(logits.dtype)\n",
        "            batch_probs = softmax(logits)\n",
        "            batch_preds = torch.argmax(batch_probs, dim=1)\n",
        "            #print(batch_preds)\n",
        "        for pred in batch_preds:\n",
        "            y_preds.append(int(pred.item()))\n",
        "        for label in batch_labels:\n",
        "            ys.append(int(label.item()))\n",
        "\n",
        "    accuracy = accuracy_score(y_preds, ys)\n",
        "    precision = precision_score(y_preds, ys, average='macro')\n",
        "    recall = recall_score(y_preds, ys, average='macro')\n",
        "    f1_macro = f1_score(y_preds, ys, average='macro')\n",
        "    f1_micro = f1_score(y_preds, ys, average='micro')\n",
        "    print(f'Epoch {epoch+1}: Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Macro: {f1_macro}, F1 Micro: {f1_micro}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iElOwe5ASwr",
        "outputId": "7fa7f324-9275-4d2a-d01e-0db39a94ff23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Accuracy: 0.9159647404505387, Precision: 0.915980373907115, Recall: 0.9163266794115629, F1 Macro: 0.9158494095465145, F1 Micro: 0.9159647404505387\n"
          ]
        }
      ],
      "source": [
        "# testing\n",
        "model.to(device)\n",
        "model.eval()\n",
        "for batch in test_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        batch_labels = batch['labels']\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "            logits = outputs.logits\n",
        "            #print(logits)\n",
        "            #print(logits.shape)\n",
        "            #print(logits.device)\n",
        "            #print(logits.dtype)\n",
        "            batch_probs = softmax(logits)\n",
        "            batch_preds = torch.argmax(batch_probs, dim=1)\n",
        "            #print(batch_preds)\n",
        "        for pred in batch_preds:\n",
        "            y_preds.append(int(pred.item()))\n",
        "        for label in batch_labels:\n",
        "            ys.append(int(label.item()))\n",
        "\n",
        "accuracy = accuracy_score(y_preds, ys)\n",
        "precision = precision_score(y_preds, ys, average='macro')\n",
        "recall = recall_score(y_preds, ys, average='macro')\n",
        "f1_macro = f1_score(y_preds, ys, average='macro')\n",
        "f1_micro = f1_score(y_preds, ys, average='micro')\n",
        "print(f'Epoch {epoch+1}: Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Macro: {f1_macro}, F1 Micro: {f1_micro}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "t2D-doJoAtDk"
      },
      "outputs": [],
      "source": [
        "sentiment_classifier.save_pretrained(\"canine-s-classifier/huggingface/sentiment_classifier\")\n",
        "tokenizer.save_pretrained('canine-s-classifier/huggingface/sentiment_classifier/tokenizer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "w8a1gSrkC8ZO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "transformers.models.canine.modeling_canine.CanineForSequenceClassification"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = CanineForSequenceClassification.from_pretrained(\"sentiment_classifier/model\")\n",
        "type(model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02e03b3d8bbe4791a146e5ec2069729a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "041df3b1f5de49b094dbff6d88a5291b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "056af4b800064da183e3bc73e9f52e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07b14a7240ff4534b4cffa4ae1002c08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "196d6fb3740b49d8ad17b7117b51914c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39e3ae1c89824f91aadbb5ed3f70ef2c",
            "placeholder": "​",
            "style": "IPY_MODEL_07b14a7240ff4534b4cffa4ae1002c08",
            "value": "Map: 100%"
          }
        },
        "240dc895adcd4deebe62c586fa79a9af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39b29efcfce44182accc20c093986ae6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39e3ae1c89824f91aadbb5ed3f70ef2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "459af651996544d0b8e1990f2fb8b71c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a2d3b85d2434bfdbfd43e96287da1c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4cb178c5d0ab476c8523928e7d6f8ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f1761b1136f4bc394057324f99791d4",
            "max": 8078,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a2d3b85d2434bfdbfd43e96287da1c8",
            "value": 2020
          }
        },
        "72dd9e346ded45c5baa14cdba7b89a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f4cbfe626154dfd8544849a613453e1",
            "max": 11220,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02e03b3d8bbe4791a146e5ec2069729a",
            "value": 11220
          }
        },
        "8ca20062229242cc9e17861d8daf7292": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecdc160026404387bded81ea8a78a81c",
            "placeholder": "​",
            "style": "IPY_MODEL_c74f869346ad47a7afbcf3d89a1e6f22",
            "value": " 11220/11220 [00:11&lt;00:00, 728.42 examples/s]"
          }
        },
        "8cd3718be5584301b4feb9cd17d81b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_196d6fb3740b49d8ad17b7117b51914c",
              "IPY_MODEL_72dd9e346ded45c5baa14cdba7b89a66",
              "IPY_MODEL_8ca20062229242cc9e17861d8daf7292"
            ],
            "layout": "IPY_MODEL_39b29efcfce44182accc20c093986ae6"
          }
        },
        "8f1761b1136f4bc394057324f99791d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f4cbfe626154dfd8544849a613453e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adbd31d9e7564726a0c84ea76d2ebd06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_041df3b1f5de49b094dbff6d88a5291b",
            "placeholder": "​",
            "style": "IPY_MODEL_056af4b800064da183e3bc73e9f52e40",
            "value": " 2020/8078 [11:47&lt;30:59,  3.26it/s]"
          }
        },
        "c74f869346ad47a7afbcf3d89a1e6f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfdbd2e6996042208e85c1d0c24e56fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2256e6300344d24b3b212f7a386b70c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffc13ba68c1c4cefb543007cd90f9843",
              "IPY_MODEL_4cb178c5d0ab476c8523928e7d6f8ca3",
              "IPY_MODEL_adbd31d9e7564726a0c84ea76d2ebd06"
            ],
            "layout": "IPY_MODEL_459af651996544d0b8e1990f2fb8b71c"
          }
        },
        "ecdc160026404387bded81ea8a78a81c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffc13ba68c1c4cefb543007cd90f9843": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfdbd2e6996042208e85c1d0c24e56fa",
            "placeholder": "​",
            "style": "IPY_MODEL_240dc895adcd4deebe62c586fa79a9af",
            "value": " 25%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
